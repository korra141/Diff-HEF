{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the HEF implementation of NLL and normalisation constant "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys \n",
    "base_path = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "sys.path.append(base_path + \"/local/HarmonicExponentialBayesFitler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.filters.bayes_filter import BayesFilter \n",
    "from src.distributions.se2_distributions import SE2Gaussian\n",
    "from src.sampler.se2_sampler import se2_grid_samples\n",
    "from lie_learn.spectral.SE2FFT import SE2_FFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = (50, 50, 32)\n",
    "fft = SE2_FFT(spatial_grid_size=size,\n",
    "              interpolation_method='spline',\n",
    "              spline_order=1,\n",
    "              oversampling_factor=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/network/scratch/r/ria.arora/local/HarmonicExponentialBayesFitler/src/distributions/se2_distributions.py\u001b[0m(26)\u001b[0;36mfrom_samples\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     24 \u001b[0;31m        \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     25 \u001b[0;31m        \u001b[0;31m# Compute energy of samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 26 \u001b[0;31m        \u001b[0menergy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_energy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     27 \u001b[0;31m        \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menergy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     28 \u001b[0;31m        \u001b[0;31m# This seems redundant, but as there is a loss of information in FFT analyze due to cartesian to polar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  c\n"
     ]
    }
   ],
   "source": [
    "poses, x, y, yaw = se2_grid_samples(size)\n",
    "mu = np.array([0.1, 0.2, np.pi / 2])\n",
    "cov = np.diag([0.05, 0.05, 0.05])\n",
    "# Define distribution\n",
    "gaussian = SE2Gaussian(mu=mu, cov=cov, samples=poses, fft=fft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "def se2_grid_samples(size: Tuple[int] = (5, 5, 5),\n",
    "                     lower_bound: float = -0.5,\n",
    "                     upper_bound: float = 0.5) -> np.ndarray:\n",
    "    xs = np.linspace(lower_bound, upper_bound, size[0], endpoint=False)\n",
    "    ys = np.linspace(lower_bound, upper_bound, size[1], endpoint=False)\n",
    "    ts = np.linspace(0., 2. * np.pi, size[2], endpoint=False)\n",
    "    X, Y, T = np.meshgrid(xs, ys, ts, indexing='ij')\n",
    "    poses = np.vstack((X.flatten(), Y.flatten(), T.flatten())).T\n",
    "    return poses, X, Y, T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "poses_np, _, _, _ = se2_grid_samples(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian.normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy = gaussian.energy\n",
    "prob = gaussian.prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_cov = np.linalg.inv(cov)\n",
    "diff = poses - mu\n",
    "\n",
    "# Wrap the angular difference to [-pi, pi]\n",
    "diff[:, 2] = (diff[:, 2] + np.pi) % (2 * np.pi) - np.pi\n",
    "\n",
    "# Compute the energy\n",
    "quadratic_form = np.sum((diff @ inv_cov) * diff, axis=1)\n",
    "energy = -0.5 * quadratic_form\n",
    "energy = energy.reshape(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, _, _, _, fh = fft.analyze(energy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the normalisation constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1735137111999463"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian.l_n_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.7367828107169683\n"
     ]
    }
   ],
   "source": [
    "d = cov.shape[0]  # Dimensionality of the Gaussian distribution\n",
    "det_cov = np.linalg.det(cov)  # Determinant of the covariance matrix\n",
    "\n",
    "# Normalization constant formula\n",
    "constant = np.log((2 * np.pi) ** (d / 2) * np.sqrt(det_cov))\n",
    "print(constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, l_n_z = gaussian.compute_moments_lnz(fh,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.9839514169577657"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_n_z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For cov = 0.01, the diff between HEF normalisation constant and the gaussian normalisation constant is 0.18200 and for cov = 0.05 the diff is 0.253 and it gets worse for cov=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "poses_check = np.vstack((mu, mu+0.025, mu+0.05, mu+0.075, mu-0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.73678281 1.71803281 1.66178281 1.56803281 1.43678281]\n"
     ]
    }
   ],
   "source": [
    "prob_true = multivariate_normal.logpdf(poses_check, mean=mu, cov=cov)\n",
    "print(prob_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.22044605e-16, -1.87500000e-02, -7.50000000e-02, -1.68750000e-01,\n",
       "       -3.00000000e-01])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_true + constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_energy = np.exp(-BayesFilter.neg_log_likelihood(gaussian.eta, gaussian.l_n_z, poses, fft))\n",
    "# p_m = -BayesFilter.neg_log_likelihood(gaussian.M, 0.0, poses, fft)\n",
    "# p_moments = -BayesFilter.neg_log_likelihood(gaussian.moments, 0.0, poses, fft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37, 223, 32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussian.eta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-13.15503082])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-BayesFilter.neg_log_likelihood(gaussian.eta, 0, mu+0.05, fft) + gaussian.l_n_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.39634954])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-BayesFilter.neg_log_likelihood2(energy,0, mu-0.1, size )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the bilinear interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def bilinear_interpolate(f, x, y):\n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y)\n",
    "\n",
    "    x0 = np.floor(x).astype(int)\n",
    "    x1 = x0 + 1\n",
    "    y0 = np.floor(y).astype(int)\n",
    "    y1 = y0 + 1\n",
    "\n",
    "    x0 = np.clip(x0, 0, f.shape[1] - 1)\n",
    "    x1 = np.clip(x1, 0, f.shape[1] - 1)\n",
    "    y0 = np.clip(y0, 0, f.shape[0] - 1)\n",
    "    y1 = np.clip(y1, 0, f.shape[0] - 1)\n",
    "\n",
    "    Ia = f[y0, x0]\n",
    "    Ib = f[y1, x0]\n",
    "    Ic = f[y0, x1]\n",
    "    Id = f[y1, x1]\n",
    "\n",
    "    wa = (x1 - x) * (y1 - y)\n",
    "    wb = (x1 - x) * (y - y0)\n",
    "    wc = (x - x0) * (y1 - y)\n",
    "    wd = (x - x0) * (y - y0)\n",
    "\n",
    "    print(x0.shape, y0.shape, x1.shape, y1.shape, x.shape, y.shape)\n",
    "    print(Ia.shape, Ib.shape, Ic.shape, Id.shape)\n",
    "    print(wa.shape, wb.shape, wc.shape, wd.shape)\n",
    "\n",
    "#     return wa[..., None] * Ia + wb[..., None] * Ib + wc[..., None] * Ic + wd[..., None] * Id\n",
    "\n",
    "    return wa * Ia + wb * Ib + wc * Ic + wd * Id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,) (1,) (1,) (1,) (1,) (1,)\n",
      "(1,) (1,) (1,) (1,)\n",
      "(1,) (1,) (1,) (1,)\n",
      "Interpolated Values: [0.]\n"
     ]
    }
   ],
   "source": [
    "f = np.array([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9]\n",
    "], dtype=np.float32)\n",
    "\n",
    "# Points to interpolate\n",
    "x = np.array([ 2.0])\n",
    "y = np.array([ 0.5])\n",
    "\n",
    "# Perform bilinear interpolation\n",
    "result = bilinear_interpolate(f, x, y)\n",
    "print(\"Interpolated Values:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def bilinear_interpolate_torch(f, x, y):\n",
    "    \"\"\"\n",
    "    Perform bilinear interpolation on a 2D tensor using PyTorch.\n",
    "    \n",
    "    Parameters:\n",
    "        f (torch.Tensor): Input tensor of shape (H, W).\n",
    "        x (torch.Tensor): x-coordinates to interpolate (float tensor).\n",
    "        y (torch.Tensor): y-coordinates to interpolate (float tensor).\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: Interpolated values at the given coordinates.\n",
    "    \"\"\"\n",
    "    # Ensure x and y are tensors\n",
    "    x = x.to(f.device)\n",
    "    y = y.to(f.device)\n",
    "\n",
    "    # Get integer grid points\n",
    "    x0 = torch.floor(x).long()\n",
    "    x1 = x0 + 1\n",
    "    y0 = torch.floor(y).long()\n",
    "    y1 = y0 + 1\n",
    "\n",
    "    # Clip to valid range\n",
    "    x0 = torch.clamp(x0, 0, f.shape[1] - 1)\n",
    "    x1 = torch.clamp(x1, 0, f.shape[1] - 1)\n",
    "    y0 = torch.clamp(y0, 0, f.shape[0] - 1)\n",
    "    y1 = torch.clamp(y1, 0, f.shape[0] - 1)\n",
    "\n",
    "    # Gather values from the 2D tensor\n",
    "    Ia = f[y0, x0]  # Bottom-left\n",
    "    Ib = f[y1, x0]  # Top-left\n",
    "    Ic = f[y0, x1]  # Bottom-right\n",
    "    Id = f[y1, x1]  # Top-right\n",
    "\n",
    "    # Compute the weights for interpolation\n",
    "    wa = (x1 - x) * (y1 - y)  # Weight for Ia\n",
    "    wb = (x1 - x) * (y - y0)  # Weight for Ib\n",
    "    wc = (x - x0) * (y1 - y)  # Weight for Ic\n",
    "    wd = (x - x0) * (y - y0)  # Weight for Id\n",
    "    \n",
    "    print(x0.shape, y0.shape, x1.shape, y1.shape, x.shape, y.shape)\n",
    "    print(Ia.shape, Ib.shape, Ic.shape, Id.shape)\n",
    "    print(wa.shape, wb.shape, wc.shape, wd.shape)\n",
    "\n",
    "    # Compute the interpolated value\n",
    "    return wa * Ia + wb * Ib + wc * Ic + wd * Id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1]) torch.Size([1]) torch.Size([1]) torch.Size([1]) torch.Size([1]) torch.Size([1])\n",
      "torch.Size([1]) torch.Size([1]) torch.Size([1]) torch.Size([1])\n",
      "torch.Size([1]) torch.Size([1]) torch.Size([1]) torch.Size([1])\n",
      "Interpolated Values: tensor([0.])\n"
     ]
    }
   ],
   "source": [
    "# Input 2D tensor (e.g., image or matrix)\n",
    "f = torch.tensor([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "# Coordinates to interpolate\n",
    "x = torch.tensor([2.0])\n",
    "y = torch.tensor([0.5])\n",
    "\n",
    "# Perform interpolation\n",
    "result = bilinear_interpolate_torch(f, x, y)\n",
    "print(\"Interpolated Values:\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def bilinear_interpolate_torch_with_nan(f, x, y):\n",
    "    \"\"\"\n",
    "    Perform bilinear interpolation on a 2D tensor with `NaN` padding in PyTorch.\n",
    "    \n",
    "    Parameters:\n",
    "        f (torch.Tensor): Input tensor of shape (H, W).\n",
    "        x (torch.Tensor): x-coordinates to interpolate (float tensor).\n",
    "        y (torch.Tensor): y-coordinates to interpolate (float tensor).\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: Interpolated values at the given coordinates.\n",
    "    \"\"\"\n",
    "    # Pad the tensor with NaN\n",
    "    f = torch.nn.functional.pad(f, (1, 1, 1, 1), mode='constant', value=float('nan'))\n",
    "\n",
    "    # Adjust coordinates for the padded tensor\n",
    "    x = x + 1\n",
    "    y = y + 1\n",
    "\n",
    "    # Get integer grid points\n",
    "    x0 = torch.floor(x).long()\n",
    "    x1 = x0 + 1\n",
    "    y0 = torch.floor(y).long()\n",
    "    y1 = y0 + 1\n",
    "\n",
    "    # Gather values from the 2D tensor\n",
    "    Ia = f[y0, x0]  # Bottom-left\n",
    "    Ib = f[y1, x0]  # Top-left\n",
    "    Ic = f[y0, x1]  # Bottom-right\n",
    "    Id = f[y1, x1]  # Top-right\n",
    "    \n",
    "    print(f\"Ia {Ia}, Ib {Ib}, Ic {Ic}, Id {Id}\")\n",
    "    # Compute the weights for interpolation\n",
    "    wa = (x1 - x) * (y1 - y)  # Weight for Ia\n",
    "    wb = (x1 - x) * (y - y0)  # Weight for Ib\n",
    "    wc = (x - x0) * (y1 - y)  # Weight for Ic\n",
    "    wd = (x - x0) * (y - y0)  # Weight for Id\n",
    "    \n",
    "    print(f\"wa {wa}, wb {wb}, wc {wc}, wd {wd}\")\n",
    "\n",
    "    # Mask out NaN values\n",
    "    valid_a = ~torch.isnan(Ia)\n",
    "    valid_b = ~torch.isnan(Ib)\n",
    "    valid_c = ~torch.isnan(Ic)\n",
    "    valid_d = ~torch.isnan(Id)\n",
    "    \n",
    "    print(f\"valid_a {valid_a}, valid_b {valid_b}, valid_c {valid_c}, valid_d {valid_d}\")\n",
    "    \n",
    "\n",
    "    # Set weights to zero where values are NaN\n",
    "    wa = wa * valid_a\n",
    "    wb = wb * valid_b\n",
    "    wc = wc * valid_c\n",
    "    wd = wd * valid_d\n",
    "\n",
    "    # Normalize weights to handle missing data\n",
    "    weight_sum = wa + wb + wc + wd\n",
    "    print(\"weight_sum\", weight_sum)\n",
    "    \n",
    "    Ia = torch.where(valid_a, Ia, torch.zeros_like(Ia))\n",
    "    Ib = torch.where(valid_b, Ib, torch.zeros_like(Ib))\n",
    "    Ic = torch.where(valid_c, Ic, torch.zeros_like(Ic))\n",
    "    Id = torch.where(valid_d, Id, torch.zeros_like(Id))\n",
    "    \n",
    "#     wa = wa / (weight_sum + 1e-8)\n",
    "#     wb = wb / (weight_sum + 1e-8)\n",
    "#     wc = wc / (weight_sum + 1e-8)\n",
    "#     wd = wd / (weight_sum + 1e-8)\n",
    "\n",
    "    # Compute the interpolated value\n",
    "    result = wa * Ia + wb * Ib + wc  * Ic + wd  * Id\n",
    "    print(\"result\",result)\n",
    "    result[weight_sum == 0] = float('nan')  # If all weights are zero, output NaN\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ia tensor([7.]), Ib tensor([nan]), Ic tensor([8.]), Id tensor([nan])\n",
      "wa tensor([0.5000]), wb tensor([0.]), wc tensor([0.5000]), wd tensor([0.])\n",
      "valid_a tensor([True]), valid_b tensor([False]), valid_c tensor([True]), valid_d tensor([False])\n",
      "weight_sum tensor([1.])\n",
      "result tensor([7.5000])\n",
      "Interpolated Values: tensor([7.5000])\n"
     ]
    }
   ],
   "source": [
    "f = torch.tensor([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9]\n",
    "], dtype=torch.float32)\n",
    "\n",
    "# Coordinates to interpolate\n",
    "x = torch.tensor([0.5])\n",
    "y = torch.tensor([2])\n",
    "\n",
    "# Perform interpolation with NaN padding\n",
    "result = bilinear_interpolate_torch_with_nan(f, x, y)\n",
    "print(\"Interpolated Values:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def bilinear_interpolate_with_nan_safe(f, x, y):\n",
    "    \"\"\"\n",
    "    Perform bilinear interpolation on a 2D NumPy array with `NaN` padding,\n",
    "    safely handling `NaN` values during the computation.\n",
    "\n",
    "    Parameters:\n",
    "        f (np.ndarray): Input 2D array of shape (H, W).\n",
    "        x (np.ndarray): x-coordinates to interpolate (float array).\n",
    "        y (np.ndarray): y-coordinates to interpolate (float array).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Interpolated values at the given coordinates.\n",
    "    \"\"\"\n",
    "    # Pad the array with NaN\n",
    "    f = np.pad(f, ((1, 1), (1, 1)), mode='constant', constant_values=np.nan)\n",
    "\n",
    "    # Adjust coordinates for the padded array\n",
    "    x = np.asarray(x) + 1\n",
    "    y = np.asarray(y) + 1\n",
    "\n",
    "    # Get integer grid points\n",
    "    x0 = np.floor(x).astype(int)\n",
    "    x1 = x0 + 1\n",
    "    y0 = np.floor(y).astype(int)\n",
    "    y1 = y0 + 1\n",
    "\n",
    "    # Clip to ensure indices are within bounds\n",
    "    x0 = np.clip(x0, 0, f.shape[1] - 1)\n",
    "    x1 = np.clip(x1, 0, f.shape[1] - 1)\n",
    "    y0 = np.clip(y0, 0, f.shape[0] - 1)\n",
    "    y1 = np.clip(y1, 0, f.shape[0] - 1)\n",
    "\n",
    "    # Gather values from the 2D array\n",
    "    Ia = f[y0, x0]  # Bottom-left\n",
    "    Ib = f[y1, x0]  # Top-left\n",
    "    Ic = f[y0, x1]  # Bottom-right\n",
    "    Id = f[y1, x1]  # Top-right\n",
    "\n",
    "    # Compute the weights for interpolation\n",
    "    wa = (x1 - x) * (y1 - y)  # Weight for Ia\n",
    "    wb = (x1 - x) * (y - y0)  # Weight for Ib\n",
    "    wc = (x - x0) * (y1 - y)  # Weight for Ic\n",
    "    wd = (x - x0) * (y - y0)  # Weight for Id\n",
    "\n",
    "    # Mask NaN values\n",
    "    valid_a = ~np.isnan(Ia)\n",
    "    valid_b = ~np.isnan(Ib)\n",
    "    valid_c = ~np.isnan(Ic)\n",
    "    valid_d = ~np.isnan(Id)\n",
    "\n",
    "    # Set invalid contributions to zero\n",
    "    Ia = np.where(valid_a, Ia, 0)\n",
    "    Ib = np.where(valid_b, Ib, 0)\n",
    "    Ic = np.where(valid_c, Ic, 0)\n",
    "    Id = np.where(valid_d, Id, 0)\n",
    "\n",
    "    # Adjust weights for NaN values\n",
    "    wa = wa * valid_a\n",
    "    wb = wb * valid_b\n",
    "    wc = wc * valid_c\n",
    "    wd = wd * valid_d\n",
    "\n",
    "    # Normalize weights to handle missing data\n",
    "    weight_sum = wa + wb + wc + wd\n",
    "#     normalized_wa = wa / (weight_sum + 1e-8)\n",
    "#     normalized_wb = wb / (weight_sum + 1e-8)\n",
    "#     normalized_wc = wc / (weight_sum + 1e-8)\n",
    "#     normalized_wd = wd / (weight_sum + 1e-8)\n",
    "\n",
    "    # Compute the interpolated value\n",
    "    result = (\n",
    "        wa * Ia +\n",
    "        wb * Ib +\n",
    "        wc * Ic +\n",
    "        wd * Id\n",
    "    )\n",
    "\n",
    "    # If all weights are zero, set result to NaN\n",
    "    result[weight_sum == 0] = np.nan\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpolated Values: [7.  4.5]\n"
     ]
    }
   ],
   "source": [
    "# Input array\n",
    "f = np.array([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9]\n",
    "], dtype=np.float64)\n",
    "\n",
    "# Coordinates to interpolate\n",
    "x = np.array([1.5, 2.0])\n",
    "y = np.array([1.5, 0.5])\n",
    "\n",
    "# Perform bilinear interpolation\n",
    "result = bilinear_interpolate_with_nan_safe(f, x, y)\n",
    "print(\"Interpolated Values:\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "harmonic",
   "language": "python",
   "name": "harmonic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
