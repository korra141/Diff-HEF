{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SE2 Uncertainty Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "base_path = os.path.dirname(os.getcwd())\n",
    "\n",
    "sys.path.append(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data \n",
    "class SE2Group:\n",
    "  def __init__(self, x, y, theta):\n",
    "    self.x = x\n",
    "    self.y = y\n",
    "    self.theta = theta\n",
    "  def __add__(self, other):\n",
    "    x = self.x + other.x * np.cos(self.theta) - other.y * np.sin(self.theta)\n",
    "    y = self.y + other.y * np.cos(self.theta) + other.x * np.sin(self.theta)\n",
    "    theta = self.theta + other.theta\n",
    "    return SE2Group(x, y, theta)\n",
    "  def parameters(self):\n",
    "    return np.array([self.x, self.y, self.theta])\n",
    "  @classmethod\n",
    "  def from_parameters(cls, x, y, theta):\n",
    "    return cls(x, y, theta)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SE2SimpleSimulator:\n",
    "\n",
    "  def __init__(self, start, step, measurement_noise, motion_noise):\n",
    "    self.position = start\n",
    "    self.step = step\n",
    "    self.motion_noise = motion_noise\n",
    "    self.measurement_noise = measurement_noise\n",
    "    self.beacons = np.array(\n",
    "            [[0, 0.1],\n",
    "             [0, 0.05],\n",
    "             [0, 0.0],\n",
    "             [0, -0.05],\n",
    "             [0, -0.1]])\n",
    "    self.beacon_idx = 0\n",
    "\n",
    "  def motion(self):\n",
    "\n",
    "    self.position = self.position + self.step\n",
    "    noisy_prediction = self.step.parameters() + np.random.randn(3) * self.motion_noise\n",
    "    noisy_prediction[2] = noisy_prediction[2] % (2 * np.pi)\n",
    "    return self.position.parameters() , noisy_prediction\n",
    "\n",
    "  def measurement(self):\n",
    "\n",
    "    self._update_beacon_idx()\n",
    "    range_beacon = self.beacons[self.beacon_idx, :]\n",
    "    # Observation z_t\n",
    "    self.range_measurement = np.linalg.norm(self.position.parameters()[0:2] - range_beacon)\n",
    "    # Jitter range measurement with noise\n",
    "    self.range_measurement += np.random.normal(0.0, self.measurement_noise, 1).item()\n",
    "\n",
    "    return self.range_measurement\n",
    "\n",
    "  def _update_beacon_idx(self) -> None:\n",
    "    \"\"\"\n",
    "    Update beacon index, and cycle back to 0 if need be.\n",
    "    \"\"\"\n",
    "    self.beacon_idx += 1\n",
    "    if self.beacon_idx >= self.beacons.shape[0]:\n",
    "        self.beacon_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def random_start_pose():\n",
    "    \"\"\"\n",
    "    Generate a random start pose within the specified bounds.\n",
    "    :return: A random pose [x, y, theta] in [-0.5, 0.5] for x, y and [0, 2pi] for theta.\n",
    "    \"\"\"\n",
    "    x = np.random.uniform(-0.5, 0.5)\n",
    "    y = np.random.uniform(-0.5, 0.5)\n",
    "    theta = np.random.uniform(0, 2 * np.pi)\n",
    "    return SE2Group(x, y, theta)\n",
    "\n",
    "def generate_bounded_se2_dataset(\n",
    "    num_trajectories,\n",
    "    trajectory_length,\n",
    "    step_motion,\n",
    "    motion_noise,\n",
    "    measurement_noise,\n",
    "):\n",
    "    \"\"\"\n",
    "    Generates a dataset of SE2 trajectories and corresponding measurements within bounded space.\n",
    "\n",
    "    :param num_trajectories: Number of trajectories to generate.\n",
    "    :param trajectory_length: Number of steps per trajectory.\n",
    "    :param step_motion: Step motion [dx, dy, dtheta].\n",
    "    :param motion_noise: Noise for motion [x, y, theta].\n",
    "    :param measurement_noise: Noise for measurements [x, y, theta].\n",
    "    :param output_file: File to save the generated dataset.\n",
    "    \"\"\"\n",
    "    true_trajectories = np.ndarray((num_trajectories, trajectory_length, 3))\n",
    "    measurements = np.ndarray((num_trajectories, trajectory_length,1))\n",
    "    noisy_control = np.ndarray((num_trajectories, trajectory_length, 3))\n",
    "\n",
    "\n",
    "    for traj_id in range(num_trajectories):\n",
    "        # Initialize simulator with a random start pose\n",
    "        start_pose = random_start_pose()\n",
    "        simulator = SE2SimpleSimulator(\n",
    "            start=start_pose,\n",
    "            step=step_motion,\n",
    "            measurement_noise=measurement_noise,\n",
    "            motion_noise=motion_noise,\n",
    "        )\n",
    "\n",
    "        for step in range(trajectory_length):\n",
    "            # Simulate motion\n",
    "            motion, noisy_step = simulator.motion()\n",
    "            true_trajectories[traj_id, step, :] = motion\n",
    "            noisy_control[traj_id, step, :] = noisy_step\n",
    "\n",
    "            # Simulate measurement\n",
    "            measurement = simulator.measurement()\n",
    "            measurements[traj_id, step] = measurement\n",
    "\n",
    "            # Check bounds and reset position if out of bounds\n",
    "            current_pose = simulator.position.parameters()\n",
    "            if not (-0.5 <= current_pose[0] <= 0.5 and -0.5 <= current_pose[1] <= 0.5):\n",
    "                simulator.position = random_start_pose()\n",
    "\n",
    "\n",
    "    return true_trajectories, noisy_control, measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 50, 1]) torch.Size([10, 50, 3])\n"
     ]
    }
   ],
   "source": [
    "NUM_TRAJECTORIES = 10\n",
    "TRAJECTORY_LENGTH = 50\n",
    "STEP_MOTION = SE2Group(0.05, 0.05, np.pi / 20)\n",
    "MOTION_NOISE = np.array([0.01, 0.01, 0.005])\n",
    "MEASUREMENT_NOISE = 0.02\n",
    "batch_size = 32\n",
    "validation_split = 0.2\n",
    "\n",
    "# Generate dataset\n",
    "true_trajectories, noisy_control, measurements = generate_bounded_se2_dataset(\n",
    "    num_trajectories=NUM_TRAJECTORIES,\n",
    "    trajectory_length=TRAJECTORY_LENGTH,\n",
    "    step_motion=STEP_MOTION,\n",
    "    motion_noise=MOTION_NOISE,\n",
    "    measurement_noise=MEASUREMENT_NOISE,\n",
    ")\n",
    "# true_trajectories_flatten, noisy_control_flatten, measurements_flatten = torch.tensor(true_trajectories).view(-1, 3), torch.tensor(noisy_control).view(-1,1), torch.tensor(measurements).view(-1,1)\n",
    "measurements_torch = torch.from_numpy(measurements).type(torch.FloatTensor)\n",
    "ground_truth_torch = torch.from_numpy(true_trajectories).type(torch.FloatTensor)\n",
    "print(measurements_torch.shape, ground_truth_torch.shape)\n",
    "ground_truth_torch = torch.flatten(ground_truth_torch, start_dim=0, end_dim=1).type(torch.FloatTensor)\n",
    "measurements_torch = torch.flatten(measurements_torch, start_dim=0, end_dim=1).type(torch.FloatTensor)\n",
    "dataset = torch.utils.data.TensorDataset(ground_truth_torch, measurements_torch)\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n",
    "val_sampler = torch.utils.data.SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler, drop_last=True, shuffle=False)\n",
    "val_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=val_sampler, drop_last=True, shuffle=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send the flattened data to learn the distribution of the measurement, send ground truth and train it on the nll of the measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim=3, output_dim=(50, 50, 32), hidden_dims=[128, 256, 512]):\n",
    "        super(MLP, self).__init__()\n",
    "        self.output_dim = output_dim  # (50, 50, 32)\n",
    "\n",
    "        # Define the MLP layers\n",
    "        layers = []\n",
    "        current_dim = input_dim\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(current_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            current_dim = hidden_dim\n",
    "        \n",
    "        # Final layer\n",
    "        final_output_dim = torch.prod(torch.tensor(output_dim)).item()  # Flattened output size\n",
    "        layers.append(nn.Linear(current_dim, final_output_dim))\n",
    "        \n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Pass through the MLP\n",
    "        x = self.mlp(x)\n",
    "        \n",
    "        # Reshape to (N, 50, 50, 32)\n",
    "        x = x.view(x.size(0), *self.output_dim)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.distributions.SE2.SE2_FFT import SE2_FFT\n",
    "\n",
    "num_epochs = 100  # Number of samples\n",
    "input_dim = 3\n",
    "grid_size = (10, 10, 20)\n",
    "\n",
    "model = MLP(input_dim=1, output_dim=grid_size)\n",
    "model.train()  # Set the model to training mode\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "fft = SE2_FFT(spatial_grid_size=grid_size,\n",
    "                  interpolation_method='spline',\n",
    "                  spline_order=1,\n",
    "                  oversampling_factor=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss is nan\n",
      "Loss is nan\n",
      "Loss is nan\n",
      "Loss is nan\n",
      "Loss is nan\n",
      "Loss is nan\n",
      "Loss is nan\n",
      "Loss is nan\n",
      "Epoch 1/100, Loss: nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs is nan\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Compute loss\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(\u001b[43mfft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mneg_log_likelihood\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misnan(loss)\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss is nan\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/network/scratch/r/ria.arora/Diff-HEF/src/distributions/SE2/SE2_FFT.py:301\u001b[0m, in \u001b[0;36mSE2_FFT.neg_log_likelihood\u001b[0;34m(self, energy, pose)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;124;03mCompute point-wise synthesize the SE2 Fourier transform M at a given pose.\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;124;03m    Probability of distribution determined by Fourier coefficients (moments) at given pose\u001b[39;00m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    300\u001b[0m l_n_z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_moments_lnz(energy)\n\u001b[0;32m--> 301\u001b[0m _, _, _, _, _, eta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manalyze\u001b[49m\u001b[43m(\u001b[49m\u001b[43menergy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m b_x, b_y, b_t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspatial_grid_size\n\u001b[1;32m    303\u001b[0m \u001b[38;5;66;03m# Reshape in case single pose is provided\u001b[39;00m\n",
      "File \u001b[0;32m/network/scratch/r/ria.arora/Diff-HEF/src/distributions/SE2/SE2_FFT.py:214\u001b[0m, in \u001b[0;36mSE2_FFT.analyze\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21manalyze\u001b[39m(\u001b[38;5;28mself\u001b[39m, f):\n\u001b[1;32m    213\u001b[0m     f1c \u001b[38;5;241m=\u001b[39m shift_fft(f)\n\u001b[0;32m--> 214\u001b[0m     f1p \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresample_c2p_3d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf1c\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     f2 \u001b[38;5;241m=\u001b[39m T1FFT\u001b[38;5;241m.\u001b[39manalyze(f1p\u001b[38;5;241m.\u001b[39mconj(), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\u001b[38;5;241m.\u001b[39mconj()\n\u001b[1;32m    217\u001b[0m     m_min \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mmath\u001b[38;5;241m.\u001b[39mfloor(f2\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2.0\u001b[39m)\n",
      "File \u001b[0;32m/network/scratch/r/ria.arora/Diff-HEF/src/distributions/SE2/SE2_FFT.py:266\u001b[0m, in \u001b[0;36mSE2_FFT.resample_c2p_3d\u001b[0;34m(self, fc)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;124;03mResample a 3D function on a Cartesian grid to a polar grid.\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;124;03m:param fc: 3D function values sampled on a Cartesian grid.\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;124;03m:return: resampled function on a polar grid\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterpolation_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspline\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 266\u001b[0m     fp \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresample_c2p(fc[:, :, :, i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(fc\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m3\u001b[39m])]\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mstack(fp, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterpolation_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFourier\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m/network/scratch/r/ria.arora/Diff-HEF/src/distributions/SE2/SE2_FFT.py:266\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;124;03mResample a 3D function on a Cartesian grid to a polar grid.\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;124;03m:param fc: 3D function values sampled on a Cartesian grid.\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;124;03m:return: resampled function on a polar grid\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterpolation_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspline\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 266\u001b[0m     fp \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresample_c2p\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(fc\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m3\u001b[39m])]\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mstack(fp, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterpolation_method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFourier\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m/network/scratch/r/ria.arora/Diff-HEF/src/distributions/SE2/SE2_FFT.py:243\u001b[0m, in \u001b[0;36mSE2_FFT.resample_c2p\u001b[0;34m(self, fc)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresample_c2p\u001b[39m(\u001b[38;5;28mself\u001b[39m, fc):\n\u001b[1;32m    238\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;124;03m    Resample a function on a Cartesian grid to a polar grid.\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;124;03m    :param fc: function values sampled on a Cartesian grid.\u001b[39;00m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;124;03m    :return: resampled function on a polar grid\u001b[39;00m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 243\u001b[0m     fp_r \u001b[38;5;241m=\u001b[39m \u001b[43mmap_coordinates_torch_constant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc2p_coords\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    244\u001b[0m     fp_c \u001b[38;5;241m=\u001b[39m map_coordinates_torch_constant(fc\u001b[38;5;241m.\u001b[39mimag, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc2p_coords)\n\u001b[1;32m    245\u001b[0m     fp \u001b[38;5;241m=\u001b[39m fp_r \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39mj \u001b[38;5;241m*\u001b[39m fp_c\n",
      "File \u001b[0;32m/network/scratch/r/ria.arora/Diff-HEF/src/distributions/SE2/SE2_FFT.py:113\u001b[0m, in \u001b[0;36mmap_coordinates_torch_constant\u001b[0;34m(input_tensor, coords)\u001b[0m\n\u001b[1;32m    111\u001b[0m fa \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mempty((input_tensor\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],input_tensor\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, input_tensor\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    112\u001b[0m fa[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m input_tensor\n\u001b[0;32m--> 113\u001b[0m fa[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m input_tensor[:, \u001b[38;5;241m0\u001b[39m, :]\n\u001b[1;32m    114\u001b[0m fa[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m input_tensor[:, :, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    115\u001b[0m fa[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m input_tensor[:, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for inputs, targets in train_loader:\n",
    "        # Forward pass\n",
    "        outputs = model(targets)\n",
    "        if torch.isnan(outputs).any():\n",
    "            print(\"outputs is nan\")\n",
    "        # Compute loss\n",
    "        loss = torch.mean(fft.neg_log_likelihood(outputs, inputs))\n",
    "        if torch.isnan(loss).any():\n",
    "            print(\"Loss is nan\")\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "harmonic",
   "language": "python",
   "name": "harmonic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
